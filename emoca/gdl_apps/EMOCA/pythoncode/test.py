import torch
import os
from kivymd.app import MDApp
from kivy.uix.screenmanager import ScreenManager
from kivymd.uix.screen import MDScreen
from kivy.uix.popup import Popup
from kivy.uix.filechooser import FileChooserIconView
from kivymd.uix.filemanager import MDFileManager
from kivymd.uix.button import MDFlatButton
from kivy.animation import Animation
from kivymd.toast import toast
from kivy.metrics import dp
from kivy.core.window import Window
from kivymd.uix.menu import MDDropdownMenu
from data_preprocessing import load_data, expression_labels
from chat_bot import EmotionChatBot
from model_prediction import load_saved_models, predict_emotion
from kivy.clock import Clock
from kivy.uix.image import Image
from kivy.core.text import LabelBase
from emoji_combiner import get_combined_emoji_image
from io import BytesIO
from kivy.core.image import Image as CoreImage

LabelBase.register(name="pangram", fn_regular=r'./fonts/Pangram-Regular.otf')
Window.size = (360, 640)

class SplashScreen(MDScreen):
    pass

class MainScreen(MDScreen):
    
    def __init__(self, **kwargs):
        super().__init__(**kwargs)
        self.camera = self.ids.get('camera', None)
        self.file_manager = MDFileManager(
            exit_manager=self.exit_manager,  # Khi nh·∫•n n√∫t tho√°t ho·∫∑c back
            select_path=self.select_path,    # Khi m·ªôt t·ªáp ƒë∆∞·ª£c ch·ªçn
            preview=True,                    # ƒê·∫∑t True n·∫øu mu·ªën xem tr∆∞·ªõc t·ªáp
        )

    def file_manager_open(self):
        # camera = self.ids.get('camera', None)
        self.camera.play = False  # T·∫°m d·ª´ng camera
        self.file_manager.show('/')  # Hi·ªÉn th·ªã file manager t·ª´ th∆∞ m·ª•c g·ªëc c·ªßa filesystem
        self.manager_open = True


    def select_path(self, path):
        # ƒê√¢y l√† callback khi m·ªôt t·ªáp ƒë∆∞·ª£c ch·ªçn
        self.exit_manager()
        #toast(path)  # Hi·ªÉn th·ªã ƒë∆∞·ªùng d·∫´n t·ªáp ƒë√£ ch·ªçn
        # Now handle the selected image and perform emotion prediction
        if os.path.isfile(path):   
            self.manager.current = 'detector'
            emotion_screen = self.manager.get_screen('detector')
            emotion_screen.display_image_and_predict_emotion(path)


    def exit_manager(self, *args):
        # ƒê√≥ng file manager
        self.manager_open = False
        # camera = self.ids.get('camera', None)
        self.camera.play = True  # K√≠ch ho·∫°t l·∫°i camera
        self.file_manager.close()

    def capture(self):
        '''
        H√†m n√†y s·∫Ω ch·ª•p ·∫£nh t·ª´ Camera v√† x·ª≠ l√Ω ·∫£nh ƒë√≥.
        '''
        # camera = self.ids.get('camera', None)
        if self.camera:
            self.camera.play = False  # T·∫°m d·ª´ng camera
            filename = "capture.png"
            current_path = os.path.dirname(os.path.abspath(__file__))
            full_path = os.path.join(current_path, filename)
            self.camera.export_to_png(full_path)  # L∆∞u ·∫£nh ch·ª•p v√†o t·ªáp
            
            # Chuy·ªÉn sang m√†n h√¨nh d·ª± ƒëo√°n
            self.manager.current = 'detector'
            emotion_screen = self.manager.get_screen('detector')
            emotion_screen.display_image_and_predict_emotion(full_path)

    def on_enter(self):
        '''K√≠ch ho·∫°t l·∫°i camera khi m√†n h√¨nh hi·ªÉn th·ªã.'''
        # camera = self.ids.get('camera', None)
        if self.camera:
            self.camera.play = True

    def on_pre_leave(self):
        '''T·∫Øt camera khi chu·∫©n b·ªã r·ªùi kh·ªèi m√†n h√¨nh n√†y.'''
        # camera = self.ids.get('camera', None)
        if self.camera:
            self.camera.play = False

class EmotionDetectorScreen(MDScreen):
    emotion_menu = None
    current_image_path = None
    def display_image_and_predict_emotion(self, image_path):
        # ƒê·∫£m b·∫£o ·∫£nh ƒë√£ ƒë∆∞·ª£c t·∫£i l√™n tr∆∞·ªõc khi d·ª± ƒëo√°n
        #self.ids.image_display.source = image_path
        #self.ids.image_display.reload()  # T·∫£i l·∫°i ·∫£nh ƒë·ªÉ hi·ªÉn th·ªã
        
        # Th·ª±c hi·ªán d·ª± ƒëo√°n c·∫£m x√∫c ·ªü ƒë√¢y
        data = load_data(image_path)
        prediction = predict_emotion(data.reshape(1, -1), MDApp.get_running_app().models)
        predicted_emotion = expression_labels[prediction[0]]
        self.ids.label.text = predicted_emotion  
        MDApp.get_running_app().update_emoji_display(predicted_emotion, self)
        # Sau khi d·ª± ƒëo√°n xong, x√≥a ·∫£nh
        if os.path.exists(image_path):
            os.remove(image_path)
        
        # Get a response from the chat bot
        chat_bot = EmotionChatBot()
        bot_response = chat_bot.get_response(predicted_emotion)
        self.ids.bot_response.text = bot_response
    
    def display_combined_emoji(self, base_emoji):
        current_emoji = self.ids.emoji_label_display.text
        combined_image_data = get_combined_emoji_image(current_emoji, base_emoji)
        
        if combined_image_data:
            # Load the combined image directly from the data
            combined_image_texture = CoreImage(BytesIO(combined_image_data), ext='png').texture
            self.ids.emoji_image_display.texture = combined_image_texture
            self.ids.emoji_image_display.opacity = 1
            self.ids.emoji_label_display.opacity = 0
        else:
            print("Failed to retrieve the combined emoji image")

    def menu_item_release(self, text_item):
        # Handle the menu item release event
        self.ids.bot_response.text = text_item  # For example, updating the bot response label
        self.emotion_menu.dismiss()

        

    # def on_pre_leave(self):
    #     '''X·ª≠ l√Ω th√™m khi chu·∫©n b·ªã r·ªùi kh·ªèi EmotionDetectorScreen.'''
    #     # ƒê·∫£m b·∫£o r·∫±ng ·∫£nh ch·ª•p ƒë∆∞·ª£c x√≥a n·∫øu t·ªìn t·∫°i
    #     image_path = self.ids.image_display.source
    #     if os.path.exists(image_path):
    #         os.remove(image_path)
    
    

class EmotionDetectorApp(MDApp):
    models = None

    def build(self):
        self.title = "SentiMate"
        self.models = load_saved_models("./models", model_version="91")
        for key in self.models:
            if isinstance(self.models[key], torch.nn.Module):
                self.models[key] = self.models[key].to('cpu')
        
        sm = ScreenManager()
        sm.add_widget(SplashScreen(name='splash'))
        sm.add_widget(MainScreen(name='main'))
        sm.add_widget(EmotionDetectorScreen(name='detector'))

        # Schedule the main screen to replace splash screen after 2 seconds
        # Clock.schedule_once(lambda dt: sm.switch_to(sm.get_screen('main')), 10)
        Clock.schedule_once(self.show_main_screen, 20)
        Window.bind(on_drop_file=self.on_drop_file)
        return sm
    
    def show_main_screen(self, *args):
        self.root.current = 'main'

    def on_drop_file(self, window, file_path, x, y):
        if file_path:
            self.root.get_screen('main').choose_image([file_path.decode('utf-8')])

    def update_emoji_display(self, emotion, screen):
        emoji_mapping = {
            "Anger": "üò†",
            "Disgust": "ü§¢",
            "Fear": "üò®",
            "Happy": "üòä",
            "Neutral": "üòê",
            "Sad": "üò¢",
            "Surprise": "üòÆ",
        }
        # Here 'screen' should be the instance of EmotionDetectorScreen which has the 'ids'
        screen.ids.emoji_label_display.text = emoji_mapping.get(emotion, "")
        screen.ids.emoji_label_display.opacity = 1
        screen.ids.emoji_image_display.opacity = 0


if __name__ == '__main__':
    EmotionDetectorApp().run()